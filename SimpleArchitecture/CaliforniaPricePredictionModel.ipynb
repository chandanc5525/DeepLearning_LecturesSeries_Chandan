{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### **Prepared By: Chandan Chaudhari**\n",
        "\n",
        "#### **Github Link:https://github.com/chandanc5525**"
      ],
      "metadata": {
        "id": "b5T-fWeHGekZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Neccessary Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder,OneHotEncoder\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "d3bhqfOsGh9N"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# ======================\n",
        "# DATA LAYER (Input)\n",
        "# ======================\n",
        "def data_ingestion():\n",
        "def get_X_y(data):\n",
        "\n",
        "# ======================\n",
        "# FEATURE LAYER (Engineering)\n",
        "# ======================\n",
        "def feature_engineering(data):\n",
        "def split_data(X, y):\n",
        "\n",
        "# ======================\n",
        "# MODEL LAYER (ML Core)\n",
        "# ======================\n",
        "def train_model(X_train, y_train):\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "def save_model(model, filename):\n",
        "\n",
        "# ======================\n",
        "# ORCHESTRATION LAYER\n",
        "# ======================\n",
        "\n",
        "1. df = data_ingestion()\n",
        "2. df = feature_engineering(df)\n",
        "3. X, y = get_X_y(df)\n",
        "4. X_train, X_test, y_train, y_test = split_data(X, y)\n",
        "5. model = train_model(X_train, y_train)\n",
        "6. score = evaluate_model(model, X_test, y_test)\n",
        "7. save_model(model, 'model.pkl')\n",
        "'''\n",
        "print('Model Architecture Design for Machine Learning')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RXyWxUpAG4Fz",
        "outputId": "b92cb360-2b11-405d-bf5c-1e2abb6e519d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Architecture Design for Machine Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Step 0: Imports\n",
        "# ------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Step 1: Data Ingestion\n",
        "# ------------------------------\n",
        "def data_ingestion():\n",
        "    from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "    housing = fetch_california_housing()\n",
        "    data = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "    data['target'] = housing.target\n",
        "    return data\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Step 2: Feature Engineering\n",
        "# ------------------------------\n",
        "def feature_engineering(data):\n",
        "    data['RoomsPerHousehold'] = data['AveRooms'] / data['AveOccup']\n",
        "    data['BedroomsPerRoom'] = data['AveBedrms'] / data['AveRooms']\n",
        "    data['PopulationPerHousehold'] = data['Population'] / data['AveOccup']\n",
        "\n",
        "    # Interaction features\n",
        "    data['IncomexAge'] = data['MedInc'] * data['HouseAge']\n",
        "    data['IncomexRooms'] = data['MedInc'] * data['AveRooms']\n",
        "\n",
        "    # Polynomial features\n",
        "    data['MedInc_squared'] = data['MedInc'] ** 2\n",
        "    data['HouseAge_squared'] = data['HouseAge'] ** 2\n",
        "\n",
        "    # Binning\n",
        "    data['Income_bin'] = pd.cut(data['MedInc'], bins=5, labels=False)\n",
        "    data['Age_bin'] = pd.cut(data['HouseAge'], bins=4, labels=False)\n",
        "\n",
        "    # Log transformations\n",
        "    data['Log_MedInc'] = np.log1p(data['MedInc'])\n",
        "    data['Log_Population'] = np.log1p(data['Population'])\n",
        "\n",
        "    print(f\"Created new features. Total features now: {len(data.columns)-1}\")\n",
        "    return data\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Step 3: Split X and y\n",
        "# ------------------------------\n",
        "def get_X_y(data):\n",
        "    X = data.drop('target', axis=1)\n",
        "    y = data['target']\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Step 4: Split the Data\n",
        "# ------------------------------\n",
        "def split_data(X, y, test_size=0.3, random_state=0):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Step 5: Train the Model\n",
        "# ------------------------------\n",
        "def train_model(X_train, y_train):\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.compose import ColumnTransformer\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.impute import SimpleImputer\n",
        "\n",
        "    numeric_features = X_train.columns.tolist()\n",
        "\n",
        "    numeric_transformer = Pipeline(\n",
        "        steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[('num', numeric_transformer, numeric_features)]\n",
        "    )\n",
        "\n",
        "    model = Pipeline(\n",
        "        steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('regressor', RandomForestRegressor(random_state=42, n_estimators=100))\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Step 6: Evaluate the Model\n",
        "# ------------------------------\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    return r2, mse\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Step 7: Save the Model\n",
        "# ------------------------------\n",
        "def save_model(model, filename):\n",
        "    import joblib\n",
        "    joblib.dump(model, filename)\n",
        "    print(f\"Model saved as '{filename}'\")\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# ORCHESTRATION LAYER\n",
        "# ------------------------------\n",
        "\n",
        "# Step 1: Load data\n",
        "data = data_ingestion()\n",
        "\n",
        "# Step 2: Feature Engineering\n",
        "df = feature_engineering(data)\n",
        "\n",
        "# Step 3: Get features and target\n",
        "X, y = get_X_y(df)\n",
        "\n",
        "# Step 4: Split\n",
        "X_train, X_test, y_train, y_test = split_data(X, y)\n",
        "print(f\"Training samples: {X_train.shape[0]}, Features: {X_train.shape[1]}\")\n",
        "\n",
        "# Step 5: Train\n",
        "rf = train_model(X_train, y_train)\n",
        "\n",
        "# Step 6: Evaluate\n",
        "r2, mse = evaluate_model(rf, X_test, y_test)\n",
        "print(f\"Model R2 Score: {r2:.4f}\")\n",
        "print(f\"Model MSE: {mse:.4f}\")\n",
        "\n",
        "# Step 7: Save\n",
        "save_model(rf, 'random_forest_model_with_features.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0Nf6KGerHKL3",
        "outputId": "7fd533b9-7aa2-4b68-d692-d3d7dd92972b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new features. Total features now: 19\n",
            "Training samples: 14448, Features: 19\n",
            "Model R2 Score: 0.7930\n",
            "Model MSE: 0.2759\n",
            "Model saved as 'random_forest_model_with_features.pkl'\n"
          ]
        }
      ]
    }
  ]
}