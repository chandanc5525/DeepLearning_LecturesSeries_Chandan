{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f81a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# Paths and Config\n",
    "# -----------------------------\n",
    "DATASET_PATH = \"path_to_dataset\"  # folder containing class subfolders\n",
    "IMG_SIZE = (224, 224)           \n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Auto-detect number of classes from folders\n",
    "NUM_CLASSES = len(next(os.walk(DATASET_PATH))[1])\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Image Data Generators\n",
    "# -----------------------------\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Note: \n",
    "\n",
    "=========================================================================\n",
    "IMAGE CLASSIFICATION LOSS FUNCTIONS EXPLAINED\n",
    "=========================================================================\n",
    "\n",
    "1. Multi-Class Classification (NUM_CLASSES > 2)\n",
    "\n",
    "   - Problem type:\n",
    "     You have more than 2 classes, e.g., CIFAR-10 (10 classes), CUB-200 (200 classes), flowers dataset (5 classes), etc.\n",
    "\n",
    "   - Labels:\n",
    "     One-hot encoded vectors:\n",
    "       Example: If 3 classes, class 2 label -> [0,1,0]\n",
    "\n",
    "   - Model Output Layer:\n",
    "       Dense(NUM_CLASSES, activation='softmax')\n",
    "       - Softmax ensures all output probabilities sum to 1\n",
    "       - Each neuron corresponds to probability of one class\n",
    "\n",
    "   - Loss Function:\n",
    "       'categorical_crossentropy'\n",
    "       Formula:\n",
    "           Loss = -Σ (y_i * log(p_i))\n",
    "           Where y_i = actual label (0 or 1)\n",
    "                 p_i = predicted probability for class i\n",
    "                 Σ = sum over all classes\n",
    "       Behavior:\n",
    "           - Initial loss depends on number of classes: ~ ln(NUM_CLASSES)\n",
    "           - For 10 classes: ~2.3, for 200 classes: ~5.3\n",
    "           - Loss decreases as model predictions become closer to actual labels\n",
    "\n",
    "   - When to use 'sparse_categorical_crossentropy':\n",
    "       - If labels are integers (0,1,2,...N-1) instead of one-hot\n",
    "       - Model output still uses softmax\n",
    "\n",
    "=========================================================================\n",
    "2. Binary Classification (NUM_CLASSES = 2)\n",
    "\n",
    "   - Problem type:\n",
    "     Only 2 classes, e.g., dogs vs cats, tumor vs normal, yes/no predictions\n",
    "\n",
    "   - Labels:\n",
    "       Single scalar per sample:\n",
    "       Example: dog=1, cat=0\n",
    "\n",
    "   - Model Output Layer:\n",
    "       Dense(1, activation='sigmoid')\n",
    "       - Sigmoid outputs probability of class 1\n",
    "       - Range: [0,1]\n",
    "\n",
    "   - Loss Function:\n",
    "       'binary_crossentropy'\n",
    "       Formula:\n",
    "           Loss = - [ y * log(p) + (1-y) * log(1-p) ]\n",
    "           Where y = actual label (0 or 1)\n",
    "                 p = predicted probability of class 1\n",
    "       Behavior:\n",
    "           - Initial loss ≈ 0.693 (~ -ln(0.5)) for random predictions\n",
    "           - Loss decreases as model predicts correct class\n",
    "\n",
    "   - Prediction:\n",
    "       - pred_class = 1 if pred > 0.5 else 0\n",
    "       - Use threshold 0.5 for sigmoid output\n",
    "\n",
    "=========================================================================\n",
    "3. Notes on Loss and Accuracy\n",
    "\n",
    "   - Loss measures \"how wrong the model is\", accuracy measures \"how many predictions are correct\"\n",
    "   - High loss = poor predictions, Low loss = predictions closer to actual\n",
    "   - For multi-class, initial loss depends on number of classes\n",
    "   - For binary, initial loss starts near 0.693\n",
    "   - Always monitor both loss and accuracy during training\n",
    "   - Data augmentation, batch size, learning rate, and network complexity affect loss trends\n",
    "\n",
    "=========================================================================\n",
    "4. Summary Table\n",
    "\n",
    "   Problem Type        | Output Layer        | Loss Function\n",
    "   ------------------- | ----------------- | ----------------------\n",
    "   Multi-class (N>2)   | Dense(N, softmax) | categorical_crossentropy\n",
    "   Multi-class int lbl | Dense(N, softmax) | sparse_categorical_crossentropy\n",
    "   Binary (2 classes)  | Dense(1, sigmoid) | binary_crossentropy\n",
    "\n",
    "=========================================================================\n",
    "5. Practical Tips\n",
    "\n",
    "   - For binary classification with ImageDataGenerator:\n",
    "       class_mode='binary'\n",
    "   - For multi-class classification with ImageDataGenerator:\n",
    "       class_mode='categorical'\n",
    "   - Start with a simple CNN architecture and gradually increase depth\n",
    "   - Use Dropout for regularization to reduce overfitting\n",
    "   - Use appropriate batch size and epochs depending on dataset size\n",
    "   - Always normalize pixel values (0-255 → 0-1)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "=========================================================================\n",
    "COMMON CNN ARCHITECTURES AND WHEN TO USE THEM\n",
    "=========================================================================\n",
    "\n",
    "1. SIMPLE CNN (Custom Small CNN)\n",
    "---------------------------------\n",
    "- Structure:\n",
    "    - 2-3 Conv2D layers with ReLU activation\n",
    "    - MaxPooling2D after each Conv2D\n",
    "    - Flatten → Dense layers → Output\n",
    "- Use case:\n",
    "    - Small datasets or beginner projects (MNIST, CIFAR-10)\n",
    "    - Quick prototyping\n",
    "    - Less computational resources\n",
    "- Pros:\n",
    "    - Simple, easy to understand\n",
    "    - Fast to train\n",
    "- Cons:\n",
    "    - Limited accuracy on complex datasets\n",
    "    - Cannot capture very deep features\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "2. VGG16 / VGG19\n",
    "-----------------\n",
    "- Structure:\n",
    "    - Deep stack of 3x3 Conv layers (16 or 19 weight layers)\n",
    "    - MaxPooling after each block\n",
    "    - Fully connected layers at the end\n",
    "- Use case:\n",
    "    - Medium-sized datasets\n",
    "    - When high accuracy is desired and GPU resources are available\n",
    "    - Transfer learning: pretrained weights on ImageNet\n",
    "- Pros:\n",
    "    - Simple uniform architecture\n",
    "    - Works well with transfer learning\n",
    "- Cons:\n",
    "    - Very heavy (large number of parameters)\n",
    "    - Slow training\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "3. ResNet (Residual Networks)\n",
    "-----------------------------\n",
    "- Structure:\n",
    "    - Residual blocks with skip connections\n",
    "    - Allows very deep networks (50, 101, 152 layers)\n",
    "- Use case:\n",
    "    - Large datasets (ImageNet, CIFAR-100)\n",
    "    - Complex image classification problems\n",
    "    - Avoid vanishing gradient problem in deep networks\n",
    "- Pros:\n",
    "    - Deep architectures without degradation\n",
    "    - High accuracy\n",
    "- Cons:\n",
    "    - More complex to implement from scratch\n",
    "    - Slower inference for very deep versions\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "4. Inception (GoogLeNet / InceptionV3)\n",
    "---------------------------------------\n",
    "- Structure:\n",
    "    - Parallel convolution paths (1x1, 3x3, 5x5)\n",
    "    - Concatenation of outputs\n",
    "- Use case:\n",
    "    - Complex datasets where multi-scale feature extraction is beneficial\n",
    "    - Large datasets with high variability\n",
    "- Pros:\n",
    "    - Efficient feature extraction at multiple scales\n",
    "    - Good accuracy with relatively smaller model size\n",
    "- Cons:\n",
    "    - Complex architecture\n",
    "    - Harder to modify for custom datasets\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "5. MobileNet / EfficientNet\n",
    "---------------------------\n",
    "- Structure:\n",
    "    - Depthwise separable convolutions (MobileNet)\n",
    "    - Efficient scaling of width, depth, and resolution (EfficientNet)\n",
    "- Use case:\n",
    "    - Edge devices, mobile applications, embedded systems\n",
    "    - When computation and memory are limited\n",
    "- Pros:\n",
    "    - Lightweight, fast inference\n",
    "    - Good trade-off between accuracy and efficiency\n",
    "- Cons:\n",
    "    - Slightly lower accuracy than heavy models on very complex datasets\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "6. DenseNet\n",
    "-----------\n",
    "- Structure:\n",
    "    - Dense blocks: each layer connects to all previous layers\n",
    "- Use case:\n",
    "    - When you want feature reuse and efficient gradient flow\n",
    "    - Medium to large datasets\n",
    "- Pros:\n",
    "    - Fewer parameters than ResNet for similar depth\n",
    "    - Excellent feature propagation\n",
    "- Cons:\n",
    "    - More memory usage during training\n",
    "    - Slightly slower than simple CNNs\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "7. When to Choose What\n",
    "-----------------------\n",
    "- Small dataset & simple task → Small custom CNN\n",
    "- Limited resources → MobileNet / EfficientNet\n",
    "- Medium dataset & transfer learning → VGG / ResNet\n",
    "- Complex dataset & very deep model → ResNet / DenseNet / Inception\n",
    "- Multi-scale feature importance → Inception\n",
    "- Real-time inference needed → MobileNet / EfficientNet\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "8. Transfer Learning Tips\n",
    "-------------------------\n",
    "- Use pretrained weights on ImageNet for medium/large datasets\n",
    "- Freeze base layers and train top layers first\n",
    "- Fine-tune later if dataset is large enough\n",
    "- Benefits:\n",
    "    - Faster convergence\n",
    "    - Higher accuracy with fewer data\n",
    "\n",
    "=========================================================================\n",
    "SUMMARY\n",
    "- CNN choice depends on:\n",
    "    - Dataset size\n",
    "    - Number of classes\n",
    "    - Computational resources\n",
    "    - Required inference speed\n",
    "- For general image classification projects, you can start with:\n",
    "    - Small CNN for experimentation\n",
    "    - VGG/ResNet for robust solutions\n",
    "    - MobileNet/EfficientNet for deployment on low-resource devices\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Build CNN Model\n",
    "# -----------------------------\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Train Model\n",
    "# -----------------------------\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Plot Accuracy and Loss\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Predict a Single Image\n",
    "# -----------------------------\n",
    "class_names = list(train_data.class_indices.keys())\n",
    "\n",
    "def preprocess_image(img_path, img_size=IMG_SIZE):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img / 255.0\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "# Example: pick first image from first class folder\n",
    "first_class = os.listdir(DATASET_PATH)[0]\n",
    "test_image_path = os.path.join(DATASET_PATH, first_class, os.listdir(os.path.join(DATASET_PATH, first_class))[0])\n",
    "\n",
    "img_input = preprocess_image(test_image_path)\n",
    "pred_probs = model.predict(img_input)\n",
    "pred_idx = np.argmax(pred_probs)\n",
    "pred_class = class_names[pred_idx]\n",
    "\n",
    "print(\"Predicted Class:\", pred_class)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(cv2.imread(test_image_path), cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Predicted: \" + pred_class)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
